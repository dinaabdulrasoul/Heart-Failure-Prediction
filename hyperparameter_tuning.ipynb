{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "experiment_name = 'heart_failure_hyperdrive'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a compute cluster or using an existing one\n",
    "\n",
    "cluster_name = \"notebook134413\" #Remember to change cluster name!\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output = True, min_node_count = 1, timeout_in_minutes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "data = Dataset.get_by_name(ws, name = 'heart_failure')\n",
    "data = data.to_pandas_dataframe()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "**Model**   \n",
    "Here Logistic Regression algorithm is used, which is a supervisied binary classification algorithm that predicts the probability of a target varaible, returning either 1 or 0 (yes or no).  \n",
    "\n",
    "**Parameter Sampler**  \n",
    "* Here we use RandomParamaterSampler to determine the best values of the hyperparameters: **regularization strength, C** and **maximum number of iterations, max_iter**. \n",
    "* In this sampling algorithm, parameter values are randomly chosen from a set of discrete values or a distribution over a continuous range. Random Sampling is a great sampler to avoid bias, usually achieves great performance and it helps in discovering new hyperparameter values.\n",
    "* Regularization strength is sampled over a uniform distribution with a minimum value of 0.5 and max value of 1, while the maximum number of iteration is sampled from a dicrete set of values which are 16, 32, 64 or 128.\n",
    "\n",
    "\n",
    "**Early Stopping Policy**  \n",
    "For this pipeline, Bandit Policy has been used, which is an early termination policy based on slack criteria, and the evaluation interval.\n",
    "* Slack_factor is the ratio used to calculate the allowed distance from the best performing experiment run.  \n",
    "* Evaluation_interval is the frequency for applying the policy.    \n",
    "*The benefits of this stopping policy* is that any run that doesn't fall within the slack factor will be terminated so this helps us in making sure the experiment doesn't run for too long and burn up a lot of resources while trying to find the optimal paramater value. \n",
    "\n",
    "**Hyperdrive Configuration Settings**  \n",
    "The HyperDriveConfig was configured using the chosen parameter sampler, early stopping policy, primary metric which is the *accuracy* and an estimator created for the training script *train.py*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "from azureml.train.hyperdrive import choice\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Specify a Policy\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=2,slack_factor=0.2)\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps =  RandomParameterSampling( {\n",
    "        \"--C\": uniform(0.5, 1),\n",
    "        \"--max_iter\": choice(16, 32, 64, 128)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "#if \"training\" not in os.listdir():\n",
    "#    os.mkdir(\"./training\")\n",
    "#sklearn_env = Environment.get(workspace=ws, name=\"AzureML-Tutorial\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "#src = ScriptRunConfig(source_directory='.',\n",
    "#                      script='train.py',\n",
    "#                      compute_target = compute_target,\n",
    "#                      environment=sklearn_env)\n",
    "\n",
    "script = 'train.py'\n",
    "est = SKLearn(source_directory='.', entry_script=script ,compute_target = compute_target)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(run_config = est,\n",
    "                             hyperparameter_sampling=ps,\n",
    "                             policy = early_termination_policy,\n",
    "                             primary_metric_name = \"Accuracy\",\n",
    "                             primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                             max_total_runs = 50,\n",
    "                             max_concurrent_runs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperdrive_run = exp.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get your best run and save the model from that run.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "# Details about the best run\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['Accuracy'])\n",
    "print(best_run.get_details()['runDefinition']['arguments'])\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# Registering the model\n",
    "model = best_run.register_model(workspace = ws, model_name='hyperdrive_model',model_path='outputs/hyperdrive_model.pkl'\n",
    "                               tags={'Training context':'Hyperdrive'},\n",
    "                            properties={'Accuracy': best_run_metrics['Accuracy']},\n",
    "                                model_framework=Model.Framework.SCIKITLEARN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "joblib.dump(model,'outputs/hyperdrive_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
